{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "* Challenges with current code\n",
    "* Understanding Pipeline\n",
    "* Solving Problems using Pipeline\n",
    "* Challenges with Pipeline\n",
    "* Solving hetrogenous data problem with ColumnTransformer\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges with current code\n",
    "* Dev have to do manually the preprocessing followed by putting the data in the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_tf = ss.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_rf.fit(trainX_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 1, 8, 6, 6, 1, 1, 8, 8, 4, 1, 1, 8, 1, 0, 8, 1, 1, 0, 8, 6,\n",
       "       2, 9, 8, 1, 9, 0, 6, 9, 6, 8, 8, 8, 0, 8, 1, 8, 8, 8, 8, 1, 8, 1,\n",
       "       8, 6, 1, 8, 0, 8, 9, 1, 8, 8, 8, 1, 6, 8, 0, 1, 1, 0, 8, 1, 9, 1,\n",
       "       0, 1, 1, 1, 9, 8, 8, 6, 1, 1, 1, 1, 0, 8, 8, 1, 1, 9, 8, 1, 9, 0,\n",
       "       8, 9, 9, 9, 0, 2, 9, 1, 1, 1, 8, 1, 1, 1, 0, 8, 0, 1, 9, 9, 8, 8,\n",
       "       9, 9, 8, 8, 8, 9, 8, 8, 9, 1, 9, 1, 8, 8, 1, 0, 1, 1, 8, 8, 8, 8,\n",
       "       4, 8, 8, 0, 0, 8, 1, 1, 6, 1, 8, 8, 8, 0, 1, 8, 1, 0, 9, 8, 0, 8,\n",
       "       8, 9, 1, 9, 1, 1, 1, 1, 8, 0, 1, 8, 8, 8, 1, 0, 6, 6, 1, 1, 8, 1,\n",
       "       8, 8, 1, 0, 1, 1, 2, 1, 1, 1, 6, 0, 0, 9, 8, 8, 0, 1, 1, 8, 1, 9,\n",
       "       8, 8, 1, 9, 1, 1, 8, 1, 9, 9, 0, 9, 1, 8, 8, 8, 8, 8, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 8, 0, 1, 8, 8, 0, 6, 9, 8, 8, 9, 6, 9, 9, 8, 6, 1, 4,\n",
       "       1, 0, 1, 2, 1, 1, 1, 8, 1, 9, 8, 8, 8, 8, 1, 8, 0, 1, 8, 1, 8, 8,\n",
       "       1, 8, 1, 9, 0, 1, 8, 0, 0, 8, 8, 1, 8, 1, 1, 4, 8, 8, 1, 8, 1, 4,\n",
       "       9, 8, 8, 9, 9, 8, 1, 8, 1, 8, 8, 0, 1, 9, 1, 1, 8, 1, 1, 0, 0, 9,\n",
       "       0, 8, 1, 8, 9, 2, 8, 1, 1, 6, 1, 1, 8, 8, 8, 0, 0, 9, 9, 6, 8, 8,\n",
       "       8, 1, 0, 1, 1, 9, 1, 1, 8, 8, 1, 8, 6, 8, 6, 0, 8, 1, 0, 9, 0, 1,\n",
       "       1, 1, 1, 1, 8, 9, 8, 6, 1, 8, 1, 8, 1, 1, 8, 8, 9, 4, 1, 0, 0, 1,\n",
       "       8, 1, 1, 9, 8, 8, 8, 9, 1, 0, 8, 9, 8, 0, 9, 1, 0, 1, 8, 8, 1, 9,\n",
       "       1, 0, 8, 8, 8, 2, 9, 8, 1, 8, 8, 1, 8, 1, 0, 8, 6, 1, 6, 9, 8, 9,\n",
       "       6, 1, 1, 9, 8, 1, 1, 8, 0, 9, 9, 1, 1, 1, 6, 8, 9, 8, 1, 8, 1, 8,\n",
       "       0, 8, 9, 8, 8, 9, 1, 1, 1, 9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is incorrect, testX isn't tranformed\n",
    "classifier_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX_tf = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 4, 6, 6, 9, 7, 8, 3, 4, 7, 2, 3, 1, 4, 2, 1, 7, 0, 7, 6,\n",
       "       2, 9, 2, 2, 9, 0, 6, 5, 6, 6, 2, 8, 4, 4, 1, 6, 8, 8, 8, 7, 5, 1,\n",
       "       6, 6, 8, 6, 4, 3, 5, 7, 3, 7, 1, 1, 6, 1, 0, 8, 1, 0, 8, 4, 8, 4,\n",
       "       0, 4, 5, 1, 5, 7, 6, 6, 8, 8, 1, 4, 4, 6, 7, 4, 3, 9, 3, 8, 3, 0,\n",
       "       3, 3, 3, 3, 0, 2, 9, 7, 1, 7, 8, 4, 1, 8, 0, 2, 4, 7, 9, 3, 3, 2,\n",
       "       3, 9, 9, 7, 1, 9, 2, 9, 3, 6, 5, 3, 0, 7, 4, 4, 4, 4, 2, 5, 5, 3,\n",
       "       4, 2, 7, 0, 0, 5, 5, 6, 6, 1, 1, 9, 6, 4, 8, 8, 4, 0, 5, 2, 7, 2,\n",
       "       3, 9, 5, 3, 8, 1, 6, 5, 2, 0, 9, 6, 8, 8, 1, 4, 6, 6, 1, 1, 3, 1,\n",
       "       2, 6, 2, 0, 1, 1, 2, 3, 8, 3, 6, 0, 0, 9, 1, 1, 0, 6, 6, 5, 4, 9,\n",
       "       3, 8, 3, 3, 8, 1, 8, 4, 9, 9, 0, 9, 0, 2, 2, 9, 3, 9, 8, 8, 4, 1,\n",
       "       0, 0, 6, 4, 3, 0, 6, 8, 8, 4, 6, 9, 3, 2, 9, 6, 9, 7, 2, 6, 7, 4,\n",
       "       1, 4, 1, 2, 1, 8, 6, 7, 5, 5, 8, 7, 3, 6, 1, 6, 7, 1, 6, 1, 3, 8,\n",
       "       4, 2, 9, 9, 0, 5, 5, 4, 0, 7, 8, 7, 1, 0, 4, 4, 6, 7, 5, 8, 4, 4,\n",
       "       9, 3, 3, 9, 9, 8, 8, 8, 2, 2, 8, 0, 1, 2, 1, 2, 6, 9, 3, 4, 0, 3,\n",
       "       4, 9, 1, 5, 9, 2, 1, 1, 1, 6, 1, 0, 8, 3, 5, 4, 6, 9, 9, 6, 8, 1,\n",
       "       8, 9, 0, 1, 5, 9, 7, 4, 1, 2, 1, 3, 6, 3, 6, 4, 3, 8, 0, 3, 0, 5,\n",
       "       8, 4, 4, 7, 8, 7, 7, 6, 7, 2, 4, 7, 1, 4, 2, 8, 3, 4, 4, 0, 0, 0,\n",
       "       2, 9, 1, 9, 7, 1, 7, 3, 7, 4, 9, 9, 2, 0, 9, 5, 0, 4, 5, 6, 1, 9,\n",
       "       1, 0, 8, 8, 3, 2, 7, 2, 8, 8, 7, 2, 9, 0, 0, 1, 6, 5, 6, 9, 7, 9,\n",
       "       5, 1, 1, 7, 8, 5, 8, 8, 0, 9, 3, 5, 8, 1, 6, 8, 7, 7, 1, 4, 7, 6,\n",
       "       0, 8, 9, 9, 8, 9, 0, 5, 2, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Difference can be seen in prediction from above\n",
    "classifier_rf.predict(testX_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "* Different features need differnt preprocessing\n",
    "* It's very cumbersome to do things the current way\n",
    "* We have to preserve manually all the preprocessors used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "* It connects preprocessor & estimators & thus removes the need to store them manually\n",
    "* In same line, the code will perform all necessary preprocessing steps, fitting the model or calling predict.\n",
    "* Easy for others to understand flow\n",
    "* Can enforce order in which transformation need to happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_pipeline = make_pipeline(StandardScaler(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = digit_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 2.46077769e-03, 2.13059145e-02, 1.08566759e-02,\n",
       "       9.56557049e-03, 2.17057235e-02, 7.23178930e-03, 8.29459303e-04,\n",
       "       1.50834140e-05, 1.29031968e-02, 2.68956343e-02, 7.62118856e-03,\n",
       "       1.35133751e-02, 2.83827148e-02, 5.11118499e-03, 4.84355497e-04,\n",
       "       2.09312651e-05, 6.79529398e-03, 1.92449643e-02, 2.21976694e-02,\n",
       "       2.97058107e-02, 5.54491603e-02, 8.43355284e-03, 2.95639716e-04,\n",
       "       5.05047414e-05, 1.27543496e-02, 4.48833603e-02, 2.29610665e-02,\n",
       "       3.46062642e-02, 2.54385126e-02, 3.40863397e-02, 1.63826471e-05,\n",
       "       0.00000000e+00, 2.65928324e-02, 2.51825922e-02, 1.96636166e-02,\n",
       "       3.80834579e-02, 2.16252406e-02, 2.35551152e-02, 0.00000000e+00,\n",
       "       2.80168676e-05, 1.01590821e-02, 3.82182630e-02, 4.03858633e-02,\n",
       "       2.14827606e-02, 1.91752770e-02, 1.85481322e-02, 3.43112346e-05,\n",
       "       2.14660464e-05, 3.02546124e-03, 1.59820883e-02, 2.07988302e-02,\n",
       "       1.34202851e-02, 2.63070239e-02, 2.38844124e-02, 1.68153982e-03,\n",
       "       1.62378818e-05, 1.53988008e-03, 2.01280156e-02, 1.12828466e-02,\n",
       "       2.47398946e-02, 3.05928269e-02, 1.39042587e-02, 4.11792457e-03])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature importance: assigning a score to input features based on their usefulness in predicting the target variable\n",
    "digit_pipeline.steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting Pipeline with Hyper-parameter Tuning\n",
    "* We could determine the best combination of hyper-parameters for preprocessor & estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* f_classif (ANOVA: Analysis of Variance) returns a p-value for each feature\n",
    "* first 10 features with the lowest p-values\n",
    "* The p-value is the probability that the null hypothesis is true. That's it.\n",
    "* null hypothesis: which states that there is no change in the revenue as a result of the new marketing campaign, is true. If the value of the p-value is 0.25, then there is a 25% probability that there is no real increase or decrease in revenue as a result of the new marketing campaign. If the value of the p-value is 0.04 then there is a 4% probability that there is no real increase or decrease in revenue as a result of the new marketing campaign. As you can surmise, the lower the p-value, the more confident we are that the alternate hypothesis is true, which, in this case, means that the new marketing campaign causes an increase or decrease in revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "digit_pipeline = make_pipeline(StandardScaler(), SelectKBest(k=10, score_func=f_classif), RandomForestClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('selectkbest', SelectKBest()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RISHBANS\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [ 0 32 39] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\RISHBANS\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('selectkbest', SelectKBest()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = digit_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8955555555555555"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = {'selectkbest__k':[20,30,40], 'randomforestclassifier__n_estimators':[100,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'selectkbest__k':[50,55,60, 90], 'randomforestclassifier__n_estimators':[200,250]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(digit_pipeline, param_grid=params, cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RISHBANS\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [ 0 32 39] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\RISHBANS\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('selectkbest', SelectKBest()),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'randomforestclassifier__n_estimators': [200, 250],\n",
       "                         'selectkbest__k': [50, 55, 60, 90]})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestclassifier__n_estimators': 250, 'selectkbest__k': 55}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9740162467300013"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.predict(testX[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('selectkbest',\n",
       "                 SelectKBest(k=55,\n",
       "                             score_func=<function f_classif at 0x7efd7e3d3f28>)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=200, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Transformer for dealing with hetrogenous data\n",
    "* Regular Pipeline intends to do same processing for all the columns\n",
    "* This doesn't work for hetrogenous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/edyoda/Data-Scientist-program/blob/master/Assignment/images/ColumnTranformer.png?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data = pd.read_csv('https://raw.githubusercontent.com/edyoda/data-science-complete-tutorial/master/Data/HR_comma_sep.csv.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data.rename(columns={'sales':'dept'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.94</td>\n",
       "      <td>6</td>\n",
       "      <td>285</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12579</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8683</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4</td>\n",
       "      <td>213</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4</td>\n",
       "      <td>263</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>technical</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.68</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "309                  0.10             0.94               6   \n",
       "12579                0.39             0.55               2   \n",
       "8683                 0.23             0.96               4   \n",
       "12495                0.82             0.99               4   \n",
       "4451                 0.87             0.68               5   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "309                     285                   4              0     1   \n",
       "12579                   159                   3              0     1   \n",
       "8683                    213                   4              0     0   \n",
       "12495                   263                   6              0     1   \n",
       "4451                    187                   3              0     0   \n",
       "\n",
       "       promotion_last_5years       dept  salary  \n",
       "309                        0    support  medium  \n",
       "12579                      0  technical    high  \n",
       "8683                       0  technical  medium  \n",
       "12495                      0  technical  medium  \n",
       "4451                       0      sales     low  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = hr_data.drop(columns=['left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_data = hr_data.left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Differnt columns needs differnt preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = feature_data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction_level       float64\n",
       "last_evaluation          float64\n",
       "number_project             int64\n",
       "average_montly_hours       int64\n",
       "time_spend_company         int64\n",
       "Work_accident              int64\n",
       "promotion_last_5years      int64\n",
       "dept                      object\n",
       "salary                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#satisfaction_level & last_evaluation don't need preprocessing\n",
    "#number_project,average_montly_hours,time_spend_company,Work_accident,promotion_last_5years need MinMaxScaler\n",
    "#dept & Salary need OrdinalEncoder\n",
    "feature_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_data = feature_data.select_dtypes(include=['float'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation\n",
       "0                0.38             0.53\n",
       "1                0.80             0.86\n",
       "2                0.11             0.88\n",
       "3                0.72             0.87"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data = feature_data.select_dtypes(include=['int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_pipeline = make_pipeline(SimpleImputer(),OrdinalEncoder())\n",
    "#SimpleImpter is for handling missing data in pipeline\n",
    "\n",
    "cat_pipeline = make_pipeline(OrdinalEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_pipeline = make_pipeline(MinMaxScaler(), SelectKBest(k=3,score_func=f_classif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "              (cat_pipeline,cat_data.columns),\n",
    "              (int_pipeline,int_data.columns),\n",
    "              remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessor, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,testX, trainY, testY = train_test_split(feature_data, target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>dept</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14443</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.83</td>\n",
       "      <td>6</td>\n",
       "      <td>244</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accounting</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12791</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4</td>\n",
       "      <td>276</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "14443                0.11             0.83               6   \n",
       "12791                0.82             0.49               4   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  \\\n",
       "14443                   244                   4              0   \n",
       "12791                   276                   4              0   \n",
       "\n",
       "       promotion_last_5years        dept salary  \n",
       "14443                      0  accounting    low  \n",
       "12791                      0     support    low  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awantik/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('ordinalencoder',\n",
       "                                                                   OrdinalEncoder(categories='auto',\n",
       "                                                                                  dtype=<class 'numpy.float64'>))],\n",
       "                                                           verbose=False),\n",
       "                                                  Index(['dept', 'salary'], dtype='object')),\n",
       "                                                 ('pipe...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(testX[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pipeline-1', Pipeline(memory=None,\n",
       "           steps=[('ordinalencoder',\n",
       "                   OrdinalEncoder(categories='auto',\n",
       "                                  dtype=<class 'numpy.float64'>))],\n",
       "           verbose=False), Index(['dept', 'salary'], dtype='object')),\n",
       " ('pipeline-2', Pipeline(memory=None,\n",
       "           steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "                  ('selectkbest',\n",
       "                   SelectKBest(k=3,\n",
       "                               score_func=<function f_classif at 0x7efd7e3d3f28>))],\n",
       "           verbose=False), Index(['number_project', 'average_montly_hours', 'time_spend_company',\n",
       "         'Work_accident', 'promotion_last_5years'],\n",
       "        dtype='object'))]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.steps[0][1].transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'columntransformer__pipeline-2__selectkbest__k':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipeline, param_grid=params, n_jobs=4, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('columntransformer',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='passthrough',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('pipeline-1',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('ordinalencoder',\n",
       "                                                                                          OrdinalEncoder(categories='auto',\n",
       "                                                                                                         dtype=<class 'numpy.float64'>))],\n",
       "                                                                                  ve...\n",
       "                                                               min_impurity_split=None,\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=10,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=4,\n",
       "             param_grid={'columntransformer__pipeline-2__selectkbest__k': [2,\n",
       "                                                                           3]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer__pipeline-2__selectkbest__k': 3}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847986487687794"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages of Pipeline\n",
    "* Doesn't support Online Learning\n",
    "* Online Learning will be discussed later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalanced data in pipeline\n",
    "* Use imblearn make_pipeline rather than scikit make_pipeline as RandomOverSampler is not supported in scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11428\n",
       "1     3571\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This make_pipeline is not scikit pipeline but imblearn pipeline which support Oversampler as part of pipeline\n",
    "pipeline = make_pipeline(preprocessor, RandomOverSampler(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awantik/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('ordinalencoder',\n",
       "                                                                   OrdinalEncoder(categories='auto',\n",
       "                                                                                  dtype=<class 'numpy.float64'>))],\n",
       "                                                           verbose=False),\n",
       "                                                  Index(['dept', 'salary'], dtype='object')),\n",
       "                                                 ('pipe...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
